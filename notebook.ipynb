{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2acabac3-1319-441d-81b3-2e1a6f7f36ac",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 9,
    "lastExecutedAt": 1766051250970,
    "lastExecutedByKernel": "860171dd-4f86-45e1-84d7-a34ba1ed62e8",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "\"\"\"# Run this cell to install the necessary packages\nimport subprocess\nimport pkg_resources\n\ndef install_if_needed(package, version):\n    '''Function to ensure that the libraries used are consistent to avoid errors.'''\n    try:\n        pkg = pkg_resources.get_distribution(package)\n        if pkg.version != version:\n            raise pkg_resources.VersionConflict(pkg, version)\n    except (pkg_resources.DistributionNotFound, pkg_resources.VersionConflict):\n        subprocess.check_call([\"pip\", \"install\", f\"{package}=={version}\"])\n\ninstall_if_needed(\"langchain-core\", \"0.3.72\")\ninstall_if_needed(\"langchain-openai\", \"0.3.28\")\ninstall_if_needed(\"langchain-community\", \"0.3.27\")\ninstall_if_needed(\"unstructured\", \"0.18.11\")\ninstall_if_needed(\"langchain-chroma\", \"0.2.5\")\ninstall_if_needed(\"langchain-text-splitters\", \"0.3.9\")\ninstall_if_needed(\"pydantic\", \"2.11.9\")\"\"\"",
    "outputsMetadata": {
     "0": {
      "height": 467,
      "type": "stream"
     },
     "1": {
      "height": 374,
      "type": "stream"
     },
     "2": {
      "height": 467,
      "type": "stream"
     },
     "3": {
      "height": 164,
      "type": "stream"
     },
     "4": {
      "height": 467,
      "type": "stream"
     },
     "5": {
      "height": 248,
      "type": "stream"
     },
     "6": {
      "height": 467,
      "type": "stream"
     },
     "7": {
      "height": 206,
      "type": "stream"
     },
     "8": {
      "height": 467,
      "type": "stream"
     },
     "9": {
      "height": 227,
      "type": "stream"
     },
     "10": {
      "height": 467,
      "type": "stream"
     },
     "11": {
      "height": 248,
      "type": "stream"
     },
     "12": {
      "height": 467,
      "type": "stream"
     },
     "13": {
      "height": 290,
      "type": "stream"
     },
     "14": {
      "height": 38,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Run this cell to install the necessary packages\\nimport subprocess\\nimport pkg_resources\\n\\ndef install_if_needed(package, version):\\n    \\'\\'\\'Function to ensure that the libraries used are consistent to avoid errors.\\'\\'\\'\\n    try:\\n        pkg = pkg_resources.get_distribution(package)\\n        if pkg.version != version:\\n            raise pkg_resources.VersionConflict(pkg, version)\\n    except (pkg_resources.DistributionNotFound, pkg_resources.VersionConflict):\\n        subprocess.check_call([\"pip\", \"install\", f\"{package}=={version}\"])\\n\\ninstall_if_needed(\"langchain-core\", \"0.3.72\")\\ninstall_if_needed(\"langchain-openai\", \"0.3.28\")\\ninstall_if_needed(\"langchain-community\", \"0.3.27\")\\ninstall_if_needed(\"unstructured\", \"0.18.11\")\\ninstall_if_needed(\"langchain-chroma\", \"0.2.5\")\\ninstall_if_needed(\"langchain-text-splitters\", \"0.3.9\")\\ninstall_if_needed(\"pydantic\", \"2.11.9\")'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Run this cell to install the necessary packages\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "\n",
    "def install_if_needed(package, version):\n",
    "    '''Function to ensure that the libraries used are consistent to avoid errors.'''\n",
    "    try:\n",
    "        pkg = pkg_resources.get_distribution(package)\n",
    "        if pkg.version != version:\n",
    "            raise pkg_resources.VersionConflict(pkg, version)\n",
    "    except (pkg_resources.DistributionNotFound, pkg_resources.VersionConflict):\n",
    "        subprocess.check_call([\"pip\", \"install\", f\"{package}=={version}\"])\n",
    "\n",
    "install_if_needed(\"langchain-core\", \"0.3.72\")\n",
    "install_if_needed(\"langchain-openai\", \"0.3.28\")\n",
    "install_if_needed(\"langchain-community\", \"0.3.27\")\n",
    "install_if_needed(\"unstructured\", \"0.18.11\")\n",
    "install_if_needed(\"langchain-chroma\", \"0.2.5\")\n",
    "install_if_needed(\"langchain-text-splitters\", \"0.3.9\")\n",
    "install_if_needed(\"pydantic\", \"2.11.9\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db001989",
   "metadata": {},
   "source": [
    "# CarManual_RAG_Assistant Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf201ea",
   "metadata": {},
   "source": [
    "# Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61baf413-6464-4c1c-a52d-b3764c124602",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 47,
    "lastExecutedAt": 1766051251017,
    "lastExecutedByKernel": "860171dd-4f86-45e1-84d7-a34ba1ed62e8",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Import the required packages\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\nfrom langchain_community.document_loaders import UnstructuredHTMLLoader\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom langchain_chroma import Chroma\nimport os"
   },
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import UnstructuredHTMLLoader\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a545ff49-6da6-4f5d-8372-5182e61ce998",
   "metadata": {},
   "source": [
    "# Load the HTML File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bed58c70-1315-409c-a590-a4c7af3cad80",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 49,
    "lastExecutedAt": 1766051251066,
    "lastExecutedByKernel": "860171dd-4f86-45e1-84d7-a34ba1ed62e8",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "loader = UnstructuredHTMLLoader(file_path=\"data/mg-zs-warning-messages.html\")\ncar_docs = loader.load()"
   },
   "outputs": [],
   "source": [
    "loader = UnstructuredHTMLLoader(file_path=\"data/mg-zs-warning-messages.html\")\n",
    "car_docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443c9a9e-9542-41a2-afbd-dfa9496b4e00",
   "metadata": {},
   "source": [
    "# Load the Models\n",
    "\n",
    "Initialize the LLM (gpt-4o-mini) and embeddings model (text-embedding-3-small)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d09bd6c4-a307-4991-98ef-cde7b9c02d8b",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 182,
    "lastExecutedAt": 1766051251249,
    "lastExecutedByKernel": "860171dd-4f86-45e1-84d7-a34ba1ed62e8",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\nembeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\", openai_api_key=os.environ[\"OPENAI_API_KEY\"])"
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\", openai_api_key=os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ad0388-9967-4355-a085-6a571aa6cf23",
   "metadata": {},
   "source": [
    "# Split Document into Chunks\n",
    "\n",
    "Split the manual into 1000-character chunks with 200-character overlap for better retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "636184c7-8491-4bcb-93c5-6c22dd6f8c2b",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 47,
    "lastExecutedAt": 1766051251297,
    "lastExecutedByKernel": "860171dd-4f86-45e1-84d7-a34ba1ed62e8",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "rc_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=1000,\n    chunk_overlap=200)\ndocs = rc_splitter.split_documents(car_docs)"
   },
   "outputs": [],
   "source": [
    "rc_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200)\n",
    "docs = rc_splitter.split_documents(car_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de290f3f-bea0-42d4-9d1c-4072f66d76b5",
   "metadata": {},
   "source": [
    "# Create Vector Store and Retriever\n",
    "\n",
    "Store document chunks in ChromaDB and create a retriever for similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aaf6c122-7d10-4e2e-899c-8960ad612842",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 1017,
    "lastExecutedAt": 1766051252314,
    "lastExecutedByKernel": "860171dd-4f86-45e1-84d7-a34ba1ed62e8",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "vectorstore = Chroma.from_documents(docs, embedding=embeddings, ids=ids)\nretriever = vectorstore.as_retriever(search_type=\"similarity\")"
   },
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(docs, embedding=embeddings, ids=ids)\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbd3f85-2b81-45be-8bd2-26c5665cf1f5",
   "metadata": {},
   "source": [
    "# Build a Prompt Template\n",
    "\n",
    "Define instructions for the LLM to answer questions using only retrieved context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bdad8ea-0da9-46d8-94e4-c5f1df381d5c",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 53,
    "lastExecutedAt": 1766051252369,
    "lastExecutedByKernel": "860171dd-4f86-45e1-84d7-a34ba1ed62e8",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "message = \"\"\"\nYou are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\nQuestion: {question} \nContext: {context} \nAnswer:\n\"\"\"\nprompt_template = ChatPromptTemplate.from_messages([(\"human\", message)])"
   },
   "outputs": [],
   "source": [
    "message = \"\"\"\n",
    "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_messages([(\"human\", message)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39066edb-d6d7-4a30-b558-241a769319b4",
   "metadata": {},
   "source": [
    "# Build and Test the RAG Chain\n",
    "\n",
    "Chain together the retriever, prompt template, and LLM to create the complete RAG pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f99140a5-656e-4a06-828c-69a86e6b6570",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 2193,
    "lastExecutedAt": 1766051254563,
    "lastExecutedByKernel": "860171dd-4f86-45e1-84d7-a34ba1ed62e8",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "rag_chain = ({\"context\": retriever, \"question\": RunnablePassthrough()}\n| prompt_template\n| llm)\nanswer = rag_chain.invoke(\"The Gasoline Particular Filter Full warning has appeared. What does this mean and what should I do about it?\").content\nprint(answer)",
    "outputsMetadata": {
     "0": {
      "height": 59,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Gasoline Particular Filter Full warning indicates that the gasoline particular filter is full. You should consult an MG Authorised Repairer as soon as possible for assistance.\n"
     ]
    }
   ],
   "source": [
    "rag_chain = ({\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "| prompt_template\n",
    "| llm)\n",
    "answer = rag_chain.invoke(\"The Gasoline Particular Filter Full warning has appeared. What does this mean and what should I do about it?\").content\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
